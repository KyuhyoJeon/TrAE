{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from Models import ConvEncoder, ConvDecoder, mlpEncoder, mlpDecoder, TrAE, Classifier, TrLSTM, TrLinear\n",
    "from Dataset import TrajectoryDataset, data_provider\n",
    "\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import easydict\n",
    "\n",
    "args = easydict.EasyDict({\n",
    "    'is_training': 1,\n",
    "    'model': 'A', # ['A', 'B']\n",
    "    ### data loader\n",
    "    'root_path': './Data/',\n",
    "    'data_path': '3D/new/csv/',\n",
    "    'checkpoints': './checkpoints/',\n",
    "    'Nsamples': 500, \n",
    "    ### forecasting task\n",
    "    'seq_len': 2656,\n",
    "    'label_len': 100,\n",
    "    'pred_len': 100,\n",
    "    'class_num': 5,\n",
    "    'individual': False,\n",
    "    ### transformer\n",
    "    'layer_num': 1,\n",
    "    'dropout': 0.1,\n",
    "    'max_len': 5000,\n",
    "    'd_model': 512,\n",
    "    'd_h': 8,\n",
    "    'd_ff': 2048,\n",
    "    ### Layers\n",
    "    'input_channel': 23,\n",
    "    't': 4, \n",
    "    'output_channel': 23,\n",
    "    'do_predict': True,\n",
    "    ### optimization\n",
    "    'num_workers': 8,\n",
    "    'itr': 1,\n",
    "    'train_epochs': 10,\n",
    "    'batch_size': 32,\n",
    "    'patience': 3,\n",
    "    'lr': 0.0005,\n",
    "    ### GPU\n",
    "    'device': 'cuda:0',\n",
    "    'use_gpu': True,\n",
    "    'multi_gpu': True,\n",
    "})\n",
    "\n",
    "args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(args.device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-Dimensional Trajectory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원본 .pickle 로드 및 전처리 후 .npy 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 2144, 5), (2000, 1), 0.24863266944885254)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "'''\n",
    "Trajectory types: Normal, autopilot_lag, LOSrate_bias, LOSrate_delay\n",
    "Target distance = uniform(4500, 5500)\n",
    "states = [x, y, vm, path_angle] + 1 control input, 5 states\n",
    "label = 0, 1, 2, 3 for normal, autopilot_lag, LOSrate_bias, LOSrate_delay respectively, 4 classes\n",
    "minimum length of trajectory = 1360 (1360*0.01 = 13.6 seconds)\n",
    "maximum length of trajectory = 2131 (2131*0.01 = 21.31 seconds)\n",
    "fixed sequence length = 2144 (2400*0.01 = 24 seconds)\n",
    "'''\n",
    "start = time.time()\n",
    "with open('Data/2D/Trajectories.pickle', 'rb') as f:\n",
    "    Dataset = pickle.load(f)\n",
    "\n",
    "# normal = Dataset['normal_PNG']\n",
    "# lag = Dataset['autopilot_lag']\n",
    "# bias = Dataset['LOSrate_bias']\n",
    "# delay = Dataset['LOSrate_delay']\n",
    "seq_len = 2144\n",
    "\n",
    "label = 0\n",
    "x = []\n",
    "y = []\n",
    "for tr_type in Dataset:\n",
    "    states = Dataset[tr_type]['states']\n",
    "    inputs = Dataset[tr_type]['actions']\n",
    "    for i in range(len(states)):\n",
    "        tr = np.concatenate((states[i], np.insert(inputs[i], 0, 0).reshape(-1 ,1)), axis=1)\n",
    "        terminal = tr[-1].copy()\n",
    "        terminal[2]=terminal[4]=0\n",
    "        tr = np.concatenate((tr, np.tile(terminal, (seq_len-len(tr), 1))), axis=0)\n",
    "        x.append(tr)\n",
    "        y.append(label)\n",
    "    label += 1\n",
    "x = np.array(x)\n",
    "y = np.array(y).reshape(-1, 1)\n",
    "np.save('Data/2D/x.npy', x)\n",
    "np.save('Data/2D/y.npy', y)\n",
    "# x = np.load('Data/2D/x.npy')\n",
    "# y = np.load('Data/2D/y.npy')\n",
    "x.shape, y.shape, time.time()-start"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".npy 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 2144, 5), (2000, 1), 4.354981899261475)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.load('Data/2D/x.npy')\n",
    "y = np.load('Data/2D/y.npy')\n",
    "x.shape, y.shape, time.time()-start"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-Dimentional Trajectory old version"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원본 .pickle 로드 및 전처리 후 .npy 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((700, 4576, 16), (700, 1), 438.2133049964905)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Trajectory types: Normal, Burn time, Xcp position, Thrust Tilt Angle, Fin bias\n",
    "Target Distance = 4000\n",
    "States = ['Accm_1', 'Accm_2', 'Accm_3', 'angEuler_1', 'angEuler_2', 'angEuler_3', 'Rmi_1', 'Rmi_2', 'Rmi_3', 'Vmi_1', 'Vmi_2', 'Vmi_3', 'Accm_Cmd_1', 'Accm_Cmd_2', 'Accm_Cmd_3', 'PhiCmd'], 16 states\n",
    "label = [0, 1, 2, 3, 4] for normal, burn_time, xcp_pos, thrust_tilt, fin_bias respectively, 5 classes\n",
    "minimum length of trajectory = 412 (412*0.01 = 4.12 seconds)\n",
    "maximum length of trajectory = 4569 (4569*0.01 = 45.69 seconds)\n",
    "fixed sequence length = 4576 (4576*0.01 = 45.76 seconds)\n",
    "'''\n",
    "start = time.time()\n",
    "seq_len = 4576\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for i, tr_type in enumerate(['Normal', 'Burntime', 'Xcpposition', \"ThrustTiltAngle\", 'Finbias']):\n",
    "    gid = pd.read_excel(f'Data/3D/old/Gid_{i+1}.xlsx', sheet_name=None)\n",
    "    msl = pd.read_excel(f'Data/3D/old/Msl_{i+1}.xlsx', sheet_name=None)\n",
    "    \n",
    "    for sheet in gid:\n",
    "        tr = pd.merge(msl[sheet][['Time', 'Rmi_1', 'Rmi_2', 'Rmi_3', 'Vmi_1', 'Vmi_2', 'Vmi_3', 'Accm_1', 'Accm_2', 'Accm_3', 'angEuler_1', 'angEuler_2', 'angEuler_3']], gid[sheet][['Time', 'Accm_Cmd_1', 'Accm_Cmd_2', 'Accm_Cmd_3', 'Phi_Cmd']]).to_numpy()[:, 1:]\n",
    "        terminal = tr[-1].copy()\n",
    "        terminal[3]=terminal[4]=terminal[5]=terminal[6]=terminal[7]=terminal[8]=terminal[12]=terminal[13]=terminal[14]=terminal[15]=0\n",
    "        tr = np.concatenate((tr, np.tile(terminal, (seq_len-len(tr), 1))), axis=0)\n",
    "        if sheet == 'Sheet1' and tr_type == 'Normal':\n",
    "            x = [tr for _ in range(140)]\n",
    "            y = [i for _ in range(140)]\n",
    "        else:\n",
    "            x.append(tr)\n",
    "            y.append(i)\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y).reshape(-1, 1)\n",
    "np.save('Data/3D/x_old.npy', x)\n",
    "np.save('Data/3D/y_old.npy', y)\n",
    "# x = np.load('Data/3D/x_old.npy')\n",
    "# y = np.load('Data/3D/y_old.npy')\n",
    "x.shape, y.shape, time.time()-start"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".npy 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((700, 4576, 16), (700, 1), 0.07254505157470703)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "x = np.load('Data/3D/x_old.npy')\n",
    "y = np.load('Data/3D/y_old.npy')\n",
    "x.shape, y.shape, time.time()-start"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-Dimensional Trajectory new version"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원본 .pickle 로드 및 전처리 후 .npy 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2500, 2656, 23), (2500, 1), 16.053280115127563)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Trajectory types: Normal, Burn time, Xcp position, Thrust Tilt Angle, Fin bias\n",
    "Target Distance = 4000\n",
    "Total states = ['Rmi_1', 'Rmi_2', 'Rmi_3', 'Vmi_1', 'Vmi_2', 'Vmi_3', 'Wmb_1', 'Wmb_2', 'Wmb_3', 'Accm_1', 'Accm_2', 'Accm_3', 'angEuler_1', 'angEuler_2', 'angEuler_3', 'FinOut_1', 'FinOut_2', 'FinOut_3', 'FinOut_4', 'err_FinBias_1', 'err_FinBias_2', 'err_FinBias_3', 'err_FinBias_4', 'FinCmd_1', 'FinCmd_2', 'FinCmd_3', 'FinCmd_4', 'err_BurnTime', 'err_Tilt_1', 'err_Tilt_2', 'err_delXcp'], 31 states\n",
    "Used States = ['Rmi_1', 'Rmi_2', 'Rmi_3', 'Vmi_1', 'Vmi_2', 'Vmi_3', 'Wmb_1', 'Wmb_2', 'Wmb_3', 'Accm_1', 'Accm_2', 'Accm_3', 'angEuler_1', 'angEuler_2', 'angEuler_3', 'FinOut_1', 'FinOut_2', 'FinOut_3', 'FinOut_4', 'FinCmd_1', 'FinCmd_2', 'FinCmd_3', 'FinCmd_4'], 23 states\n",
    "label = [0, 1, 2, 3, 4] for normal, burn_time, xcp_pos, thrust_tilt, fin_bias respectively, 5 classes\n",
    "minimum length of trajectory = 2449 (2448*0.01 = 24.48 seconds)\n",
    "maximum length of trajectory = 2635 (2635*0.01 = 26.35 seconds)\n",
    "fixed sequence length = 2656 (2656*0.01 = 26.56 seconds)\n",
    "'''\n",
    "start = time.time()\n",
    "seq_len = 2656\n",
    "x = []\n",
    "y = []\n",
    "tr = {}\n",
    "for i, tr_type in enumerate(['Normal', 'Burntime', 'Xcpposition', \"ThrustTiltAngle\", 'Finbias']):\n",
    "    N = 1 if i == 0 else 500\n",
    "    for tr_i in range(N):\n",
    "        tr = pd.read_csv(f'Data/3D/new/csv/Type_{i+1}_{tr_i+1}.csv', header=None)\n",
    "        tr.columns = ['Rmi_1', 'Rmi_2', 'Rmi_3', 'Vmi_1', 'Vmi_2', 'Vmi_3', 'Wmb_1', 'Wmb_2', 'Wmb_3', 'Accm_1', 'Accm_2', 'Accm_3', 'angEuler_1', 'angEuler_2', 'angEuler_3', 'FinOut_1', 'FinOut_2', 'FinOut_3', 'FinOut_4', 'err_FinBias_1', 'err_FinBias_2', 'err_FinBias_3', 'err_FinBias_4', 'FinCmd_1', 'FinCmd_2', 'FinCmd_3', 'FinCmd_4', 'err_BurnTime', 'err_Tilt_1', 'err_Tilt_2', 'err_delXcp']\n",
    "        tr = tr[['Rmi_1', 'Rmi_2', 'Rmi_3', 'Vmi_1', 'Vmi_2', 'Vmi_3', 'Wmb_1', 'Wmb_2', 'Wmb_3', 'Accm_1', 'Accm_2', 'Accm_3', 'angEuler_1', 'angEuler_2', 'angEuler_3', 'FinOut_1', 'FinOut_2', 'FinOut_3', 'FinOut_4', 'FinCmd_1', 'FinCmd_2', 'FinCmd_3', 'FinCmd_4']].to_numpy()\n",
    "        tr[0] = 4000 - tr[0]\n",
    "        terminal = tr[-1].copy()\n",
    "        terminal[3]=terminal[4]=terminal[5]=terminal[6]=terminal[7]=terminal[8]=terminal[12]=terminal[13]=terminal[14]=terminal[19]=terminal[20]=terminal[21]=terminal[22]=0\n",
    "        tr = np.concatenate((tr, np.tile(terminal, (seq_len-len(tr), 1))), axis=0)\n",
    "        if i == 0:\n",
    "            x = [tr for _ in range(500)]\n",
    "            y = [i for _ in range(500)]\n",
    "        else:\n",
    "            x.append(tr)\n",
    "            y.append(i)\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y).reshape(-1, 1)\n",
    "np.save('Data/3D/x_new.npy', x)\n",
    "np.save('Data/3D/y_new.npy', y)\n",
    "# x = np.load('Data/3D/x_new.npy')\n",
    "# y = np.load('Data/3D/y_new.npy')\n",
    "x.shape, y.shape, time.time()-start"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".npy 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2500, 2656, 23), (2500, 1), 0.24094510078430176)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "x = np.load('Data/3D/x_new.npy')\n",
    "y = np.load('Data/3D/y_new.npy')\n",
    "x.shape, y.shape, time.time()-start"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, train_loader = data_provider(args, 'train')\n",
    "valid_set, valid_loader = data_provider(args, 'valid')\n",
    "test_set, test_loader = data_provider(args, 'test')\n",
    "# next(iter(train_loader))[0].shape, next(iter(train_loader))[1].shape, len(train_loader), train_set.data_x.shape, train_set.data_y.shape\n",
    "# next(iter(valid_loader))[0].shape, next(iter(valid_loader))[1].shape, len(valid_loader), valid_set.data_x.shape, valid_set.data_y.shape\n",
    "# next(iter(test_loader))[0].shape, next(iter(test_loader))[1].shape, len(test_loader), test_set.data_x.shape, test_set.data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TrAE(ConvEncoder, ConvDecoder, args).to(args.device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=10):\n",
    "    \"\"\"\n",
    "    model: model to train\n",
    "    dataloaders: train, val, test data's loader\n",
    "    criterion: loss function\n",
    "    optimizer: optimizer to update your model\n",
    "    \"\"\"\n",
    "    since = time.time()\n",
    "\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_val_loss = 100000000\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()            # Set model to training mode\n",
    "            else:\n",
    "                model.eval()            # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(args.device).type(torch.float32).transpose(1, 2)                                       # transfer inputs to GPU \n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "                    outputs, encoded = model(inputs)\n",
    "                    loss = criterion(outputs, inputs)           # calculate a loss\n",
    "\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()                             # perform back-propagation from the loss\n",
    "                        optimizer.step()                             # perform gradient descent with given optimizer\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)                    \n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'train':\n",
    "                train_loss_history.append(epoch_loss)\n",
    "\n",
    "            if phase == 'val':\n",
    "                val_loss_history.append(epoch_loss)\n",
    "\n",
    "            if phase == 'val' and epoch_loss < best_val_loss:\n",
    "                best_val_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Loss: {:4f}'.format(best_val_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, train_loss_history, val_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "train Loss: 227597.1377\n",
      "val Loss: 227424.0960\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "train Loss: 227525.6041\n",
      "val Loss: 227083.1288\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "train Loss: 224658.2841\n",
      "val Loss: 218569.4120\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "train Loss: 185199.0598\n",
      "val Loss: 129330.0804\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "train Loss: 73509.6609\n",
      "val Loss: 45293.7700\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "train Loss: 35167.2235\n",
      "val Loss: 28129.0135\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "train Loss: 23600.1017\n",
      "val Loss: 20441.2515\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "train Loss: 18435.8797\n",
      "val Loss: 16645.3568\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "train Loss: 15292.3396\n",
      "val Loss: 13871.7712\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "train Loss: 12786.1123\n",
      "val Loss: 11686.5644\n",
      "\n",
      "Training complete in 0m 13s\n",
      "Best val Loss: 11686.564398\n"
     ]
    }
   ],
   "source": [
    "data_loaders = {'train': train_loader, 'val': valid_loader, 'test': test_loader}\n",
    "best_model, train_loss_history, val_loss_history = train_model(model, data_loaders, criterion, optimizer, num_epochs=args.train_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's draw a learning curve like below.\n",
    "plt.plot(train_loss_history, label='train')\n",
    "plt.plot(val_loss_history, label='val')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in data_loaders[\"test\"]:\n",
    "        inputs = inputs.to(args.device)\n",
    "\n",
    "        outputs, encoded = best_model(inputs)\n",
    "        test_loss = criterion(outputs, inputs)\n",
    "        \n",
    "        running_loss += test_loss.item() * inputs.size(0)\n",
    "\n",
    "    test_loss = running_loss / len(data_loaders[\"test\"].dataset)\n",
    "    print(test_loss)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
